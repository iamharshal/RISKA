{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The LogCA model\n",
    "\n",
    "This notebook constructs the [LogCA model](https://dl.acm.org/doi/pdf/10.1145/3140659.3080216) to analytically model simple host-accelerator interaction\n",
    "\n",
    "## LogCA parameters\n",
    "\n",
    "| Parameter                  | Description                                       | Units |\n",
    "|:---------------------------|:--------------------------------------------------|-------|\n",
    "|**L** - Latency             | Cycles to move data from the host to the accelerator across the interface, including the cycles data spends in the caches or memory | Cycles |\n",
    "|**o** - Overhead            | Cycles the host spends in setting up the algorithm | Cycles |\n",
    "|**g** - Granularity         | Size of the offloaded data | Bytes |\n",
    "|**C** - Computational Index | Cycles the host spends per byte of data | Cycles/Byte |\n",
    "|**A** - Acceleration        | The peak speedup of an accelerator | N/A |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the speedup for given LogCA parameters. ```complexity_power_factor``` ($ \\beta $) is the power factor of the complexity of the alogrithm as a function of granularity as per the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speedup(latency, \n",
    "            overhead, \n",
    "            granularity, \n",
    "            computational_index, \n",
    "            acceleration, \n",
    "            complexity_power_factor, \n",
    "            is_latency_granularity_depend):\n",
    "    \n",
    "    host_comp_index = computational_index * (granularity ** complexity_power_factor)\n",
    "    \n",
    "    if(is_latency_granularity_depend):\n",
    "        latency = latency * granularity\n",
    "            \n",
    "    return host_comp_index / (latency + overhead + (host_comp_index / acceleration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute break-even granularity $ g_1 $. It is the granularity required to achieve a speedup of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_even_granularity(latency, \n",
    "                           overhead, \n",
    "                           computational_index,\n",
    "                           acceleration,\n",
    "                           complexity_power_factor,\n",
    "                           is_latency_granularity_depend):\n",
    "    \n",
    "    if(is_latency_granularity_depend):\n",
    "        return ((computational_index * (complexity_power_factor - 1) * (acceleration - 1) + acceleration * overhead) / \\\n",
    "               (computational_index * complexity_power_factor * (acceleration - 1) - acceleration * latency))\n",
    "    \n",
    "    return ((acceleration / (acceleration - 1)) * ((overhead + latency) / computational_index)) ** (1 / complexity_power_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute half-speedup granularity $ g_{A/2} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_speedup_granularity(latency, \n",
    "                             overhead, \n",
    "                             computational_index,\n",
    "                             acceleration, \n",
    "                             complexity_power_factor,\n",
    "                             is_latency_granularity_depend):\n",
    "    \n",
    "    if(is_latency_granularity_depend):\n",
    "        return ((computational_index * (complexity_power_factor - 1) + acceleration * overhead) / \\\n",
    "               (computational_index * complexity_power_factor - acceleration * latency))\n",
    "    \n",
    "    return (acceleration * ((overhead + latency) / computational_index)) ** (1 / complexity_power_factor)\n",
    "\n",
    "def half_speedup_granularity(be_granularity,\n",
    "                             acceleration,\n",
    "                             complexity_power_factor):\n",
    "    \n",
    "    return ((acceleration - 1) ** (1 / complexity_power_factor)) * be_granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example system\n",
    "\n",
    "The below parameters model an APU for an FFT kernel as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup achieved with accelerator:  0.999999931135947\n",
      "Break even granularity:  148653.1099524985\n"
     ]
    }
   ],
   "source": [
    "latency = 15\n",
    "overhead = 4 * 10**8\n",
    "granularity = 148653.1\n",
    "computational_index = 290\n",
    "acceleration = 7\n",
    "complexity_power_factor = 1.2\n",
    "\n",
    "\n",
    "print(\"Speedup achieved with accelerator: \", speedup(latency, overhead, granularity, computational_index, acceleration, complexity_power_factor, False))\n",
    "print(\"Break even granularity: \", break_even_granularity(latency, overhead, computational_index, acceleration, complexity_power_factor, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup achieved with accelerator:  0.9999999912994371\n",
      "Break even granularity:  2981895.633652822\n"
     ]
    }
   ],
   "source": [
    "latency = 15\n",
    "overhead = 4 * 10**8\n",
    "granularity = 2981895.6\n",
    "computational_index = 174\n",
    "acceleration = 7\n",
    "complexity_power_factor = 1\n",
    "\n",
    "\n",
    "print(\"Speedup achieved with accelerator: \", speedup(latency, overhead, granularity, computational_index, acceleration, complexity_power_factor, True))\n",
    "print(\"Break even granularity: \", break_even_granularity(latency, overhead, computational_index, acceleration, complexity_power_factor, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple experimental model to model the performance of W-projection gridding algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "I = 10\n",
    "J = 10\n",
    "K = 10\n",
    "L = 2\n",
    "\n",
    "(DISCRETE, INTEGRATED) = (True, False)\n",
    "\n",
    "def __gridding_model__(in_latency, processing_delay, out_latency):\n",
    "    # Adjust the latency and delay numbers according to SDP Memo\n",
    "    # Please add more loops as necessary\n",
    "    time.sleep(in_latency)\n",
    "    m = 0\n",
    "    for i in range(1,I):\n",
    "        for j in range(1,J):\n",
    "            for k in range(1,K):\n",
    "                for l in range (1,L):\n",
    "                    time.sleep(processing_delay)\n",
    "                    m+=1\n",
    "    time.sleep(out_latency)\n",
    "    return m\n",
    "\n",
    "def discrete_accelerated_gridding():\n",
    "    # in_latency is high, \n",
    "    # processing delay is low (as CPUs are slower than accelerators), \n",
    "    # out_latency is high \n",
    "\n",
    "    return __gridding_model__(1.0, 0.001, 1.0)\n",
    "    \n",
    "def integrated_accelerated_gridding():\n",
    "    # in_latency is low, \n",
    "    # processing delay is low (as CPUs are slower than accelerators), \n",
    "    # out_latency is low\n",
    "    return __gridding_model__(0.001, 0.001, 0.001)\n",
    "\n",
    "def accelerated_gridding(mode):\n",
    "    if mode == DISCRETE:\n",
    "        return discrete_accelerated_gridding()\n",
    "    else:\n",
    "        return integrated_accelerated_gridding()\n",
    "\n",
    "def cpu_gridding():\n",
    "    # in_latency is low, \n",
    "    # processing delay is high (as CPUs are slower than accelerators), \n",
    "    # out_latency is low\n",
    "   return __gridding_model__(0.001, 0.01, 0.001) \n",
    "\n",
    "\n",
    "def main():\n",
    "    start = time.perf_counter()\n",
    "    cpu_gridding()\n",
    "    print(\"cpu_gridding: \", time.perf_counter() - start)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    discrete_accelerated_gridding()\n",
    "    print(\"discrete_accelerated_gridding: \", time.perf_counter() - start)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    integrated_accelerated_gridding()\n",
    "    print(\"integrated_accelerated_gridding: \", time.perf_counter() - start)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
